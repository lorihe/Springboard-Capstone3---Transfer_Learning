{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOY2fa9l9cuhlQ8C6JgJZXM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorihe/Springboard-Capstone3---Transfer_Learning/blob/main/Game_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVSzhUufMYl8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras import callbacks, optimizers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, GlobalAvgPool2D, Input\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS97mDsq3T2v",
        "outputId": "b27bb34f-71ee-4853-87a0-7709db424425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Game_Classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6AHEIv73YTu",
        "outputId": "000513e4-a656-464c-fb93-48eec346407d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Game_Classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_Data(dir_path, target_size, batch, class_lst, preprocessing):\n",
        "  \"\"\"\n",
        "    Create a data generator using ImageDataGenerator for loading and augmenting images from a directory.\n",
        "\n",
        "    Args:\n",
        "        dir_path (str): Path to the directory containing the image files organized in subdirectories.\n",
        "        target_size (tuple): A tuple specifying the target height and width of the images.\n",
        "        batch (int): The batch size for training or inference.\n",
        "        class_lst (list): List of class names. Subdirectories in 'dir_path' should be named after these classes.\n",
        "        preprocessing (function, optional): A function that is applied to each input image for preprocessing.\n",
        "            This function should take an input image (either a PIL image or a Numpy array) and return a\n",
        "            preprocessed Numpy array. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        DirectoryIterator: A DirectoryIterator yielding batches of augmented/loaded image data along with labels.\n",
        "  \"\"\"\n",
        "  if preprocessing:\n",
        "    gen_object = ImageDataGenerator(preprocessing_function = preprocessing)\n",
        "  else:\n",
        "    gen_object = ImageDataGenerator()\n",
        "\n",
        "  return(gen_object.flow_from_directory(dir_path, target_size, batch_size = batch, class_mode = 'sparse',\n",
        "                                   classes = class_lst, shuffle = True))"
      ],
      "metadata": {
        "id": "KKgF_SO58nzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = img_Data('clean_data/train', (224,224), 500, ['rugby','soccer'], preprocess_input)"
      ],
      "metadata": {
        "id": "WTdDJPdBikN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600be733-b685-4cbc-aae1-91e86958abba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2448 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data_gen = img_Data('clean_data/test', (224,224), 500, ['rugby','soccer'], preprocess_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtX8FhdAx5sI",
        "outputId": "93dc1b2e-70db-4afc-e689-83787f7e612d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 610 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use pre-trained weights to build the base model\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3), alpha=1.0, include_top=False, weights=\"imagenet\",\n",
        "    input_tensor=None, pooling=None, classes=2,\n",
        "    classifier_activation=\"softmax\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWdkuUL2yEoX",
        "outputId": "072a72cf-c733-45f0-af7e-1caed860be9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "Q27yn2Jq2VFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add customized layers\n",
        "from keras.layers.attention.multi_head_attention import activation\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAvgPool2D())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Hf47OGxq6L9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkGhqnOu_2xG",
        "outputId": "62c7aae9-9ef6-45bb-ab32-704308b8dd1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              1311744   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,579,978\n",
            "Trainable params: 1,321,994\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "elst = callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, mode = 'min')\n",
        "save_ck = callbacks.ModelCheckpoint('model.hdf5', save_best_only = True, monitor = 'val_loss', mode = 'min')"
      ],
      "metadata": {
        "id": "nEJIL8asBWFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_gen, batch_size = 500, validation_data = valid_data_gen, callbacks = [elst, save_ck], epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el7bJUk8_4m2",
        "outputId": "9e0c0a0f-2811-4d9d-9a4f-963f315cbfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 58s 12s/step - loss: 0.4019 - accuracy: 0.8456 - val_loss: 0.4205 - val_accuracy: 0.8639\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 56s 12s/step - loss: 0.3626 - accuracy: 0.8742 - val_loss: 0.2944 - val_accuracy: 0.8770\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 55s 11s/step - loss: 0.2955 - accuracy: 0.8840 - val_loss: 0.3649 - val_accuracy: 0.8770\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 57s 12s/step - loss: 0.2477 - accuracy: 0.8995 - val_loss: 0.2678 - val_accuracy: 0.8852\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 64s 14s/step - loss: 0.2200 - accuracy: 0.9118 - val_loss: 0.3226 - val_accuracy: 0.8820\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 54s 11s/step - loss: 0.1959 - accuracy: 0.9195 - val_loss: 0.2527 - val_accuracy: 0.8984\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 56s 11s/step - loss: 0.1806 - accuracy: 0.9306 - val_loss: 0.2915 - val_accuracy: 0.9000\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 55s 11s/step - loss: 0.1662 - accuracy: 0.9342 - val_loss: 0.2368 - val_accuracy: 0.9148\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 53s 11s/step - loss: 0.1556 - accuracy: 0.9432 - val_loss: 0.2691 - val_accuracy: 0.9066\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 56s 12s/step - loss: 0.1430 - accuracy: 0.9493 - val_loss: 0.2321 - val_accuracy: 0.9180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7d197ef6cd60>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gxg9T2AcEvbF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}